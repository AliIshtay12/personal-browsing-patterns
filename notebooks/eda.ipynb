{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preliminary Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# File path configuration\n",
    "file_path = '../data/raw/rawdata.tsv' \n",
    "\n",
    "# Load the dataset into a Pandas DataFrame, skipping the first line\n",
    "df = pd.read_csv(file_path, sep='\\t', skiprows=1)  # Skipping the first row due to format issues\n",
    "print(\"\\nDataset loaded successfully!\")\n",
    "\n",
    "# Step 1: Rename Columns, according to export format given with the extension's feature. \n",
    "column_names = [\n",
    "    \"URL\",              # The visited URL\n",
    "    \"Host\",             # The hostname of the URL\n",
    "    \"Domain\",           # The domain of the URL\n",
    "    \"Visit Time (ms)\",  # The visit time in milliseconds\n",
    "    \"Visit Time\",       # The visit time as a string in local time\n",
    "    \"Day of Week\",      # The day of the week for the visit time\n",
    "    \"Transition Type\",  # How the browser navigated to the URL\n",
    "    \"Page Title\"        # The title of the visited URL\n",
    "]\n",
    "\n",
    "# Assign new column names to the DataFrame\n",
    "df.columns = column_names\n",
    "print(\"\\nColumns named successfully!\")\n",
    "print(f\"Updated columns: {df.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the dataset\n",
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check data types and column information\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "\n",
    "# Investigate \"Day of Week\" as a categorical variable\n",
    "print(\"\\nDay of Week Distribution (Categorical Variable):\")\n",
    "days_of_week = {\n",
    "    0: \"Sunday\",\n",
    "    1: \"Monday\",\n",
    "    2: \"Tuesday\",\n",
    "    3: \"Wednesday\",\n",
    "    4: \"Thursday\",\n",
    "    5: \"Friday\",\n",
    "    6: \"Saturday\"\n",
    "}\n",
    "# Analyze the distribution using the mapping without modifying the dataset\n",
    "day_of_week_distribution = df['Day of Week'].map(days_of_week).value_counts()\n",
    "print(day_of_week_distribution)\n",
    "\n",
    "# Summary statistics for other categorical columns\n",
    "print(\"\\nSummary statistics for other categorical columns:\")\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_columns:\n",
    "    print(f\"\\nColumn: {col}\")\n",
    "    print(df[col].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Overview\n",
    "\n",
    "##### First Few Rows\n",
    "Columns: URL, Host, Domain, Visit Time (ms), Visit Time, Day of Week, Transition Type, Page Title\n",
    "\n",
    "##### Key Observations\n",
    "- Columns like Host, Domain, and Page Title have missing values (NaN). Which is indicated or warned by the extension's export feature.\n",
    "- URL provides the visited links, while Transition Type shows navigation type (link, typed).\n",
    "\n",
    "##### Dataset Info\n",
    "- Total Rows: 65,839(Index start from 0).\n",
    "- Total Columns: 8\n",
    "\n",
    "##### Column Types\n",
    "- float(Date/Time Data Type): 1 column (e.g., Visit Time (ms)) \n",
    "- int(Catagorical Variable): 1 column (The day of the week for the visit time. Values are 0-6. Sunday=0, Monday=1, etc.)\n",
    "- object: 6 columns\n",
    "    - URL: Identifier variable (unique for each row, represents the visited URL)\n",
    "    - Host: Categorical variable (represents the hostname of the URL)\n",
    "    - Domain: Categorical variable (represents the domain of the URL, grouped based on the public suffix)\n",
    "    - Visit Time (string): Date/Time variable (provides the exact timestamp of the visit)\n",
    "    - Transition Type: Categorical variable (indicates how the browser navigated to the URL, e.g., link, typed, reload)\n",
    "    - Page Title: Categorical variable (represents the title of the visited page)\n",
    "\n",
    "##### Non-Null Counts\n",
    "- Fully populated columns: URL, Visit Time (ms), Visit Time (String), Day of Week, Transition Type\n",
    "- Columns with missing data: Host, Domain, Page Title (As indicated by the export feature).\n",
    "\n",
    "##### Summary of Objects(Categorical/Identifier/Date) Variables\n",
    "\n",
    "###### Day of Week\n",
    "- **Distribution of days:**\n",
    "  - **Tuesday:** 11,033\n",
    "  - **Wednesday:** 10,990\n",
    "  - **Monday:** 9,766\n",
    "  - **Thursday:** 9,292\n",
    "  - **Sunday:** 8,901\n",
    "  - **Saturday:** 8,246\n",
    "  - **Friday:** 7,611\n",
    "\n",
    "###### URL\n",
    "- **Total unique URLs:** 16,812\n",
    "- **Most common URL:** https://mail.google.com/mail/u/2/#inbox (1,073 occurrences)\n",
    "\n",
    "###### Host\n",
    "- **Total unique hosts:** 1,349\n",
    "- **Most common host:** sucourse.sabanciuniv.edu (18,029 occurrences)\n",
    "\n",
    "###### Domain\n",
    "- **Total unique domains:** 1,047\n",
    "- **Most common domain:** sabanciuniv.edu (25,630 occurrences)\n",
    "\n",
    "##### Visit Time\n",
    "- **Total unique timestamps:** 56,280\n",
    "- **Most frequent timestamp:** 2024-11-04 03:35:00 (43 occurrences)\n",
    "\n",
    "###### Transition Type\n",
    "- **Types of transitions:**\n",
    "  - **link:** 49,865\n",
    "  - **generated:** 4,431\n",
    "  - **reload:** 3,540\n",
    "  - **form_submit:** 3,397\n",
    "  - **auto_bookmark:** 2,995\n",
    "  - **typed:** 1,320\n",
    "  - **auto_toplevel:** 286\n",
    "  - **manual_subframe:** 5\n",
    "\n",
    "###### Page Title\n",
    "- **Total unique titles:** 10,041\n",
    "- **Most common title:** mySU (1,647 occurrences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify missing values in each column\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values Count:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "Missing Values Count:\n",
    "- **URL:** 0\n",
    "- **Host:** 832\n",
    "- **Domain:** 1346\n",
    "- **Visit Time (ms):** 0\n",
    "- **Visit Time:** 0\n",
    "- **Day of Week:** 0\n",
    "- **Transition Type:** 0\n",
    "- **Page Title:** 396\n",
    "- **Day of Week Label:** 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with \"Unknown\"\n",
    "df.fillna(\"Unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handeling Missing Data\n",
    "\n",
    "Any missing values were replaced with \"Unknown\" for further and better data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output file path\n",
    "output_file_path = '../data/processed/processedata.csv'\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(output_file_path, index=False)  # index=False prevents adding the index column to the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Checks & Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/processed/processedata.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Remove the \"Transition Type\" and \"Visit Time (ms)\" columns\n",
    "df = df.drop(columns=['Visit Time (ms)']) \n",
    "df = df.drop(columns=['Transition Type'])\n",
    "\n",
    "# Save the updated DataFrame back to the processed data file\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operations Performed:\n",
    "\n",
    "#### Columns Removed: \n",
    "- The column `Transition Type` and `Visit Time (ms)` were removed because of there irrelevance to the analysis.\n",
    "\n",
    "#### Updated Data:\n",
    "- The changes were applied to the `processed_data` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path to the processed data\n",
    "file_path = '../data/processed/processedata.csv'\n",
    "\n",
    "# Load the processed dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Check for duplicates and count them\n",
    "duplicate_count = df.duplicated().sum()\n",
    "\n",
    "# Output the duplicate count\n",
    "print(f\"Number of duplicate rows: {duplicate_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "No duplicate rows were found in the dataset. This indicates that all rows are unique and no redundant data exists.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute Analysis\n",
    "\n",
    "Must interpret output for report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "categorical_columns = ['URL', 'Host', 'Domain', 'Page Title', 'Day of Week']\n",
    "\n",
    "# Analyze frequencies and plot bar charts for each categorical attribute\n",
    "for col in categorical_columns:\n",
    "    print(f\"\\nFrequencies for {col}:\")\n",
    "    print(df[col].value_counts().head(10))  # Display the top 10 most common values for brevity\n",
    "    \n",
    "    # Plot the top 10 values for visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    df[col].value_counts().head(10).plot(kind='bar', color='skyblue')\n",
    "    plt.title(f\"Top 10 Most Frequent Values in {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Analysis\n",
    "\n",
    "Must interpret output for report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Visit Time to datetime\n",
    "df['Visit Time (datetime)'] = pd.to_datetime(df['Visit Time'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Analyze hourly activity\n",
    "hourly_counts = df['Visit Time (datetime)'].dt.hour.value_counts().sort_index()\n",
    "\n",
    "# Plot hourly activity\n",
    "plt.figure(figsize=(10, 6))\n",
    "hourly_counts.plot(kind='bar', color='green')\n",
    "plt.title(\"Hourly Browsing Activity\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze activity by day of the week\n",
    "day_of_week_counts = df['Day of Week'].value_counts().sort_index()\n",
    "days_of_week_labels = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "\n",
    "# Plot day of week activity\n",
    "plt.figure(figsize=(10, 6))\n",
    "day_of_week_counts.index = days_of_week_labels\n",
    "day_of_week_counts.plot(kind='bar', color='orange')\n",
    "plt.title(\"Browsing Activity by Day of Week\")\n",
    "plt.xlabel(\"Day of Week\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Academic vs Non-Academic Activity Analysis\n",
    "\n",
    "Must interpret output for report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the top 50 most common domains\n",
    "top_domains = df['Domain'].value_counts().head(50)\n",
    "\n",
    "# Display the results for review\n",
    "print(\"Top 50 Most Common Domains:\")\n",
    "print(top_domains)\n",
    "\n",
    "# Helper to identify likely academic domains (e.g., containing '.edu' or research-related keywords)\n",
    "potential_academic_domains = [\n",
    "    domain for domain in top_domains.index\n",
    "    if 'edu' in domain or 'research' in domain or 'univ' in domain or 'course' in domain\n",
    "]\n",
    "\n",
    "# Print the automatically identified potential academic domains\n",
    "print(\"\\nPotential Academic Domains:\")\n",
    "print(potential_academic_domains)\n",
    "\n",
    "# Define academic domains (including the identified ones and some predefined)\n",
    "academic_domains = ['sabanciuniv.edu', 'edu', 'researchgate.net', 'gradescope.com', 'w3schools.com', \n",
    "                    'harvard.edu'] + potential_academic_domains\n",
    "\n",
    "# Categorize activity type\n",
    "df['Activity Type'] = df['Domain'].apply(\n",
    "    lambda x: 'Academic' if any(domain in str(x) for domain in academic_domains) else 'Non-Academic'\n",
    ")\n",
    "\n",
    "# Analyze and visualize activity type\n",
    "activity_counts = df['Activity Type'].value_counts()\n",
    "\n",
    "# Print results\n",
    "print(\"Activity Type Analysis:\")\n",
    "print(activity_counts)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "activity_counts.plot(kind='bar', color=['blue', 'orange'])\n",
    "plt.title(\"Academic vs Non-Academic Activity\")\n",
    "plt.xlabel(\"Activity Type\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peak Browsing Periods\n",
    "\n",
    "Must interpret output for report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Visit Time to datetime format\n",
    "df['Visit Time (datetime)'] = pd.to_datetime(df['Visit Time'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Extract hour and day of week\n",
    "df['Hour'] = df['Visit Time (datetime)'].dt.hour\n",
    "df['Day of Week'] = df['Visit Time (datetime)'].dt.dayofweek\n",
    "\n",
    "# Analyze hourly activity\n",
    "hourly_activity = df['Hour'].value_counts().sort_index()\n",
    "\n",
    "# Plot hourly activity\n",
    "plt.figure(figsize=(10, 6))\n",
    "hourly_activity.plot(kind='bar', color='green')\n",
    "plt.title(\"Browsing Activity by Hour of Day\")\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze daily activity\n",
    "daily_activity = df['Day of Week'].value_counts().sort_index()\n",
    "days_of_week_labels = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "\n",
    "# Plot daily activity\n",
    "plt.figure(figsize=(10, 6))\n",
    "daily_activity.index = days_of_week_labels\n",
    "daily_activity.plot(kind='bar', color='purple')\n",
    "plt.title(\"Browsing Activity by Day of Week\")\n",
    "plt.xlabel(\"Day of Week\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Behavioral Patterns During Academic and Leisure Days\n",
    "\n",
    "Must interpret output for report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define academic days (e.g., weekdays) and leisure days (e.g., weekends)\n",
    "df['Day Type'] = df['Day of Week'].apply(lambda x: 'Academic Day' if x in [1, 2, 3, 4, 5] else 'Leisure Day')\n",
    "\n",
    "# Categorize by activity type and day type\n",
    "behavior_patterns = df.groupby(['Day Type', 'Activity Type']).size().unstack(fill_value=0)\n",
    "\n",
    "# Print results\n",
    "print(\"Behavioral Patterns During Academic and Leisure Days:\")\n",
    "print(behavior_patterns)\n",
    "\n",
    "# Stacked bar chart for behavioral patterns\n",
    "behavior_patterns.plot(kind='bar', stacked=True, figsize=(10, 6), color=['blue', 'orange'])\n",
    "plt.title(\"Behavioral Patterns During Academic and Leisure Days\")\n",
    "plt.xlabel(\"Day Type\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.legend(title=\"Activity Type\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visit Time Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed data file\n",
    "file_path = '../data/processed/processedata.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert \"Visit Time\" to datetime format\n",
    "df['Visit Time'] = pd.to_datetime(df['Visit Time'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Extract relevant parts\n",
    "df['Visit Hour'] = df['Visit Time'].dt.hour\n",
    "df['Visit Day'] = df['Visit Time'].dt.day\n",
    "df['Visit Month'] = df['Visit Time'].dt.month\n",
    "\n",
    "# Save the updated DataFrame back to the processed data file\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date and Time Feature Engineering\n",
    "\n",
    "In this step, the `Visit Time` column, originally in string format, was transformed to extract relevant temporal features for analysis. The following changes were made:\n",
    "\n",
    "1. **Conversion to Datetime**: The `Visit Time` column was converted from a string format to a proper datetime object. This allows for easier manipulation and extraction of time-based features.\n",
    "\n",
    "2. **Feature Extraction**:\n",
    "   - **Hour**: Extracted the hour of the visit to analyze activity distribution throughout the day.\n",
    "   - **Day**: Extracted the day of the month to observe trends within a specific month.\n",
    "   - **Month**: Extracted the month of the visit to identify seasonal or monthly patterns.\n",
    "\n",
    "3. **Integration with Dataset**: The new features (`Visit Hour`, `Visit Day`, and `Visit Month`) were added as separate columns to the dataset, enhancing its usability for further exploratory and statistical analyses.\n",
    "\n",
    "These transformations are essential for temporal analysis, allowing a deeper understanding of browsing behavior over time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define exam and academic periods\n",
    "summer_classes_start = pd.to_datetime(\"2024-07-08\")\n",
    "summer_classes_end = pd.to_datetime(\"2024-08-27\")\n",
    "fall_classes_start = pd.to_datetime(\"2024-10-01\")\n",
    "\n",
    "midterm_period_start = pd.to_datetime(\"2024-07-01\")\n",
    "midterm_period_end = pd.to_datetime(\"2024-07-10\")\n",
    "finals_period_start = pd.to_datetime(\"2024-08-24\")\n",
    "finals_period_end = pd.to_datetime(\"2024-08-27\")\n",
    "fall_exam_start = pd.to_datetime(\"2024-11-01\")\n",
    "\n",
    "# Convert Visit Time to datetime\n",
    "df['Visit Time'] = pd.to_datetime(df['Visit Time'])\n",
    "\n",
    "# Temporal Features\n",
    "df['Weekday'] = df['Visit Time'].dt.weekday  # 0 = Monday, 6 = Sunday\n",
    "df['Is Weekend'] = df['Weekday'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "df['Hour'] = df['Visit Time'].dt.hour\n",
    "df['Time of Day'] = pd.cut(df['Hour'], bins=[0, 6, 12, 18, 24], labels=['Night', 'Morning', 'Afternoon', 'Evening'], right=False)\n",
    "\n",
    "# Exam-Related Features\n",
    "df['Days Until Exam'] = df['Visit Time'].apply(lambda x: (min(abs((x - midterm_period_start).days), \n",
    "                                                            abs((x - finals_period_start).days), \n",
    "                                                            abs((x - fall_exam_start).days))))\n",
    "df['During Exam Period'] = df['Visit Time'].apply(lambda x: 1 if (\n",
    "    midterm_period_start <= x <= midterm_period_end or \n",
    "    finals_period_start <= x <= finals_period_end or \n",
    "    x >= fall_exam_start) else 0)\n",
    "\n",
    "# Academic Period Features\n",
    "df['During Academic Period'] = df['Visit Time'].apply(lambda x: 1 if (\n",
    "    summer_classes_start <= x <= summer_classes_end or \n",
    "    x >= fall_classes_start) else 0)\n",
    "\n",
    "# Behavioral Patterns\n",
    "daily_activity = df.groupby(df['Visit Time'].dt.date)['URL'].count()\n",
    "daily_mean = daily_activity.mean()\n",
    "df['Browsing Spike'] = df['Visit Time'].dt.date.apply(lambda x: 1 if daily_activity.get(x, 0) > 1.5 * daily_mean else 0)\n",
    "\n",
    "# Updated academic domains\n",
    "academic_domains = [\n",
    "    'sabanciuniv.edu', 'edu', 'researchgate.net', 'gradescope.com', 'w3schools.com',\n",
    "    'harvard.edu', 'google.com', 'youtube.com', 'chatgpt.com', 'github.com',\n",
    "    'udemy.com', 'notion.so'\n",
    "]\n",
    "\n",
    "# Activity Type Feature\n",
    "df['Activity Type'] = df['Domain'].apply(\n",
    "    lambda x: 'Academic' if any(domain in str(x) for domain in academic_domains) else 'Non-Academic'\n",
    ")\n",
    "\n",
    "# Save the updated DataFrame to the processed file\n",
    "file_path = '../data/processed/processedata.csv'\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering\n",
    "\n",
    "This script is designed to enhance the dataset with new features that capture temporal patterns, exam-related activities, and academic behaviors. These engineered features are essential for understanding the relationship between browsing activity and academic cycles, aligning with the hypothesis of this project.\n",
    "\n",
    "#### Key Processes and Features Added:\n",
    "\n",
    "1. **Defining Temporal and Academic Periods:**\n",
    "   - Important dates are defined, including:\n",
    "     - **Summer classes:** From July 8, 2024, to August 27, 2024.\n",
    "     - **Fall classes:** Starting October 1, 2024.\n",
    "     - **Exam periods:** \n",
    "       - Midterms (July 1–10, 2024).\n",
    "       - Finals (August 24–27, 2024).\n",
    "       - Fall semester exams (starting November 1, 2024).\n",
    "\n",
    "2. **Conversion to DateTime Format:**\n",
    "   - The `Visit Time` column is converted to a datetime format for precise temporal calculations.\n",
    "\n",
    "3. **Temporal Features:**\n",
    "   - **Weekday:** Identifies the day of the week for each visit (0 = Monday, 6 = Sunday).\n",
    "   - **Is Weekend:** Flags visits occurring on weekends (Saturday or Sunday).\n",
    "   - **Hour of Visit:** Extracts the hour from the visit time.\n",
    "   - **Time of Day:** Categorizes visits into four time intervals:\n",
    "     - Night (00:00–06:00)\n",
    "     - Morning (06:00–12:00)\n",
    "     - Afternoon (12:00–18:00)\n",
    "     - Evening (18:00–24:00)\n",
    "\n",
    "4. **Exam-Related Features:**\n",
    "   - **Days Until Exam:** Calculates the absolute number of days until the nearest exam period (midterms, finals, or fall exams).\n",
    "   - **During Exam Period:** Flags whether the visit occurred during a defined exam period.\n",
    "\n",
    "5. **Academic Period Features:**\n",
    "   - **During Academic Period:** Flags whether the visit occurred during active class periods (summer or fall semesters).\n",
    "\n",
    "6. **Behavioral Patterns:**\n",
    "   - **Browsing Spike:** Identifies days with unusually high browsing activity, defined as days with visits exceeding 1.5 times the daily average.\n",
    "\n",
    "7. **Data Saving:**\n",
    "   - The updated dataset, with all the new features, is saved to the processed file for further analysis.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
